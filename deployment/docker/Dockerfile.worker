# Dockerfile for Knytt Celery Worker
# Optimized for ML workloads with CLIP embeddings

FROM python:3.11-slim as base

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    C_FORCE_ROOT=true

WORKDIR /app

# Install system dependencies including ML libs
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    git \
    curl \
    libpq-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# =====================================================
# Dependencies Stage
# =====================================================
FROM base as dependencies

# Copy requirements (including ML dependencies)
COPY requirements.txt .
COPY requirements-ml.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt && \
    pip install --no-cache-dir -r requirements-ml.txt

# =====================================================
# Model Download Stage
# =====================================================
FROM dependencies as model-download

# Copy backend code needed for model download
COPY backend/ml/config.py /app/backend/ml/config.py
COPY backend/ml/__init__.py /app/backend/ml/__init__.py
COPY backend/__init__.py /app/backend/__init__.py

# Create model cache directory
RUN mkdir -p /app/models/cache/clip

# Pre-download CLIP model to avoid runtime downloads
# Model: ViT-B-32, Pretrained: openai (~400MB)
RUN python3 -c "\
import sys; \
sys.path.insert(0, '/app'); \
from pathlib import Path; \
Path('models/cache/clip').mkdir(parents=True, exist_ok=True); \
import open_clip; \
model, _, preprocess = open_clip.create_model_and_transforms(\
    'ViT-B-32', \
    pretrained='openai', \
    cache_dir='models/cache/clip'\
); \
print('âœ“ CLIP model downloaded successfully')\
"

# =====================================================
# Production Stage
# =====================================================
FROM base as production

# Copy installed packages from dependencies stage
COPY --from=dependencies /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
COPY --from=dependencies /usr/local/bin /usr/local/bin

# Copy application code first
COPY backend/ /app/backend/
COPY models/ /app/models/
COPY workers/ /app/workers/

# Copy pre-downloaded models from model-download stage (overwrites empty cache)
COPY --from=model-download /app/models/cache /app/models/cache

# Create non-root user and set ownership
RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app

# Switch to non-root user
USER appuser

# Cloud Run requires a port even for workers
EXPOSE 8080

# Run a simple HTTP server for health checks alongside Celery worker
# In production, you'd run this with a process manager like supervisord
CMD python -m celery -A backend.tasks.celery_app worker \
    --loglevel=info \
    --concurrency=2 \
    --max-tasks-per-child=10 \
    --time-limit=900 \
    --soft-time-limit=840
